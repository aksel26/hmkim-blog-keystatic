---
title: '# HBM, AI 시대의 ''메모리 심장''을 해부하다'
summary: >-
  HBM(고대역폭메모리)이란? AI 반도체의 핵심 부품 HBM의 원리부터 SK하이닉스·삼성전자의 100조 경쟁까지. 2026년 HBM4 시대,
  투자자가 알아야 할 모든 것을 정리했습니다.
keywords:
  - Life
  - HBM
  - 반도체
  - HBM이란
  - 고대역폭메모리
  - HBM 관련주
status: draft
tags:
  - 반도체
  - HBM
  - 하이닉스
  - AI반도체
  - 성장주
createdAt: 2026-01-30
updatedAt: 2026-01-30
thumbnailImage: /images/thumbnails/hbm-ai/thumbnailImage.png
---
# HBM, AI 시대의 '메모리 심장'을 해부하다

"메모리 반도체? 그거 사이클 산업 아니었어?"

2년 전만 해도 이런 말이 당연했습니다. 호황과 불황을 오가며 롤러코스터를 타던 산업.

그런데 지금, 삼성전자와 SK하이닉스가 **각각 영업이익 100조 원**을 바라보고 있습니다. 그 중심에는 세 글자가 있습니다. **HBM**.

오늘은 증권 분석가이자 반도체 전문가의 시선으로, HBM이 무엇인지, 왜 이렇게 중요해졌는지, 그리고 현재 시장에서 어떤 일이 벌어지고 있는지를 정리해드리겠습니다.

---

## HBM이 뭐길래? 쉬운 설명부터

\**HBM(High Bandwidth Memory)**은 이름 그대로 "고대역폭 메모리"입니다.

비유를 하나 들어볼게요. 여러분이 대형 마트에서 장을 보는데, 카트가 하나밖에 없다고 상상해보세요. 물건을 많이 담으려면 왔다 갔다 여러 번 해야 합니다. 그런데 만약 카트 10개를 한 번에 끌고 다닐 수 있다면? 한 번에 훨씬 많은 물건을 옮길 수 있겠죠.

**HBM은 바로 이 "동시에 여러 카트를 끄는" 메모리입니다.**

기존 D램이 한 줄짜리 고속도로라면, HBM은 **8\~16차선 고속도로**입니다. 같은 시간에 훨씬 많은 데이터를 처리할 수 있죠.

### 기술적으로는 이렇습니다

HBM의 핵심은 **적층(Stacking)** 기술입니다.

{% table %}
- 구분
- 일반 D램
- HBM
---
- 구조
- 단일 칩
- 4~16개 칩 수직 적층
---
- 대역폭
- ~25GB/s
- 1~1.5TB/s
---
- 연결 방식
- PCB 기판
- TSV(실리콘 관통 전극)
---
- 주요 용도
- PC, 서버
- AI 가속기, 고성능 연산
{% /table %}

D램 칩을 **레고 블록처럼 수직으로 쌓고**, 각 층을 **TSV(Through Silicon Via)**라는 미세한 구멍으로 연결합니다. 이렇게 하면 같은 면적에서 훨씬 많은 메모리를 넣고, 데이터 통로도 넓어지죠.

---

## AI 시대, 왜 HBM이 필수가 됐나?

ChatGPT를 써보신 분들은 아실 겁니다. 대답이 꽤 빠르게 나온다는 걸요. 그 뒤에서 무슨 일이 벌어지고 있을까요?

GPT-4 같은 대형 언어 모델은 수천억 개의 파라미터를 가지고 있습니다. 이 파라미터들이 연산에 참여하려면 **모두 메모리에 올라와 있어야 합니다**. 그런데 일반 D램으로는 데이터를 GPU로 보내는 속도가 너무 느립니다.

**GPU가 아무리 빨라도, 메모리가 데이터를 못 따라가면 소용없습니다.**

이걸 업계에서는 **"메모리 병목(Memory Bottleneck)"**이라고 부릅니다. 엔비디아의 젠슨 황 CEO가 "HBM이 AI의 핵심"이라고 강조하는 이유가 여기 있습니다.

### HBM 세대별 진화

{% table %}
- 세대
- 출시
- 대역폭
- 용량
- 주요 탑재 제품
---
- HBM2e
- 2020
- 460GB/s
- 16GB
- A100
---
- HBM3
- 2022
- 819GB/s
- 24GB
- H100
---
- HBM3E
- 2024
- 1.2TB/s
- 36GB
- H200, B200
---
- HBM4
- 2026
- 2TB/s+
- 48GB+
- Rubin (예정)
{% /table %}

보시다시피, 2년마다 대역폭이 **거의 2배씩** 뛰고 있습니다. AI 모델이 커지는 속도와 맞물려, HBM 수요는 폭발적으로 증가 중입니다.

---

## 현재 시장: SK하이닉스 독주, 삼성전자의 추격

자, 이제 투자자들이 가장 궁금해하는 부분입니다. **누가 이 시장을 지배하고 있는가?**

### 2025년 3분기 HBM 시장 점유율 (카운터포인트리서치)

{% table %}
- 회사
- 점유율
---
- SK하이닉스
- 57%
---
- 삼성전자
- 22%
---
- 마이크론
- 21%
{% /table %}

SK하이닉스가 압도적입니다. 엔비디아의 AI 칩에 들어가는 HBM의 대부분을 SK하이닉스가 공급하고 있죠.

### 숫자로 보는 양사 실적 (2025년 기준)

{% table %}
- 지표
- SK하이닉스
- 삼성전자 DS부문
---
- 연간 영업이익
- 약 47조 원
- 약 23조 원
---
- HBM 시장 점유율
- 57%
- 22%
---
- 2026년 영업익 전망
- 93~101조 원
- 100조 원+
{% /table %}

**"20조 원 차이"**. SK하이닉스의 완승입니다. 하지만 2026년은 다릅니다.

### 2026년, 판도가 바뀔 수 있는 이유

**첫째, HBM4의 등장**

SK하이닉스는 2026년 2월, 세계 최초로 HBM4 양산에 돌입합니다. TSMC와 협력해 로직 다이를 12nm 공정으로 제작하고, 대역폭은 2배, 전력 효율은 40% 이상 개선됩니다.

하지만 삼성전자도 가만있지 않습니다. 삼성은 HBM4를 기점으로 **시장 반전을 노리고 있습니다**. 1c나노 D램 설계 완성, 엔비디아 HBM3E 12단 납품 공식화, 브로드컴과의 협력 확대 등 공격적인 행보를 보이고 있죠.

**둘째, 범용 D램 가격 폭등**

AI 수요가 HBM에 집중되면서, 오히려 일반 D램 공급이 줄었습니다. 결과적으로 범용 D램 가격이 급등했고, 삼성전자가 여기서 수혜를 받고 있습니다. 삼성은 애플 아이폰17향 LPDDR5X 물량의 60~70%를 확보했고, 가격도 올해 초 대비 2배 이상 올렸습니다.

**셋째, 투자 규모의 차이**

{% table %}
- 회사
- 2026년 설비투자 계획
---
- SK하이닉스
- 30조 원대 중반
---
- 삼성전자 DS
- 40조 원 이상
{% /table %}

삼성전자의 자금력이 만만치 않습니다. 평택 P4-4 구역 준공을 2027년에서 2026년 1분기로 앞당겼고, 미국 텍사스 파운드리 팹도 2nm 공정으로 전환해 가동합니다.

---

## 투자 관점: 어떻게 봐야 할까?

글로벌 투자은행 맥쿼리는 최근 보고서에서 이렇게 선언했습니다.

> "메모리 반도체 산업이 슈퍼 사이클에 진입했다. 2028년까지 유례없는 가격 상승세가 이어질 것이다."

맥쿼리가 제시한 목표 주가는 **SK하이닉스 112만 원, 삼성전자 24만 원**입니다.

### 투자 포인트 정리

**SK하이닉스의 강점**

- HBM 시장 선점 효과 (엔비디아와의 견고한 파트너십)
- HBM4 세계 최초 양산
- 2026년 순이익 100조 원 전망

**SK하이닉스의 리스크**

- 높은 감가상각비로 인한 EBITDA 열위
- 600조 원 규모 용인 클러스터 자금 조달 이슈
- PER 13배 수준의 낮은 밸류에이션 (성장주 디스카운트)

**삼성전자의 강점**

- 압도적 자금력과 안정적 현금창출력
- HBM4 기점 반격 가능성
- 범용 D램 가격 상승 수혜
- PER 25배의 안정주 프리미엄

**삼성전자의 리스크**

- HBM 시장에서의 신뢰도 열위
- 파운드리 사업부 부진
- 엔비디아 외 고객 다변화 필요

### 업계의 시각

단기적으로는 SK하이닉스의 우위가 이어질 것으로 보입니다. 하지만 삼성전자가 HBM4를 기점으로 빠르게 추격하면서, 시장은 **'양강 체제'**로 재편될 가능성이 높습니다.

중요한 점은, **AI 인프라 투자 확대로 HBM 수요가 구조적으로 증가하는 만큼, 둘 다 수혜를 볼 수 있다**는 것입니다. 이건 제로섬 게임이 아닙니다.

---

## HBM4, 그 다음은?

HBM의 진화는 멈추지 않습니다.

SK하이닉스의 김기태 HBM 세일즈&마케팅 담당은 최근 컨퍼런스콜에서 이렇게 말했습니다.

> "HBM4 역시 3나 3E와 마찬가지로 압도적인 시장 점유율을 목표하고 있다. 현재 고객 요청 물량에 대해 양산을 진행 중이다."

HBM4는 엔비디아의 차세대 AI 칩 **'루빈(Rubin)'**에 탑재될 예정입니다. 이미 그 다음 세대인 **HBM4E**에 대한 로드맵도 준비되고 있죠.

패키징 기술도 진화합니다. 현재 12단 적층에서 16단, 나아가 **하이브리드 본딩** 기술로 더 높이 쌓는 연구가 진행 중입니다. 발열 관리와 적층 한계를 극복하는 기술이 향후 점유율을 가를 핵심 변수가 될 것입니다.

---

## 마치며

HBM은 더 이상 '메모리 반도체'라는 단순한 카테고리에 머물지 않습니다. **AI 시대의 핵심 인프라**입니다.

정리하면 이렇습니다:

1. **HBM은 AI 연산의 병목을 해결하는 핵심 부품**입니다. 대역폭이 일반 D램의 40배 이상입니다.
1. **SK하이닉스가 현재 시장을 지배**하고 있지만, **삼성전자의 추격**이 본격화되고 있습니다.
1. **2026년은 HBM4의 해**입니다. 양사 모두 역대 최대 실적, 영업이익 100조 원 시대를 바라보고 있습니다.
1. **슈퍼 사이클은 시작 단계**입니다. 맥쿼리는 2028년까지 이 흐름이 이어질 것으로 전망합니다.

AI 혁명은 반도체 없이 불가능합니다. 그리고 그 반도체의 심장에는 HBM이 있습니다.
